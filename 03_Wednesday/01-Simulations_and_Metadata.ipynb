{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations and Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first things we need to know about the data are\n",
    " 1. which simulations are available, and\n",
    " 2. what physical systems those simulations represent.\n",
    "\n",
    "The answers are provided by the `Simulations` object, which contains `Metadata` for each simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "\n",
    "To begin, we load the `Simulations` object with the `sxs.load` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sxs\n",
    "\n",
    "simulations = sxs.load(\"simulations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time you call this function, it will attempt to download [the latest data from github](https://github.com/sxs-collaboration/sxs/tree/simulations) and cache it locally, as described in [the previous notebook](../00-Introduction#configuration-and-caching-preliminaries).\n",
    "\n",
    "The returned object is essentially a `dict`, where the keys are SXS IDs like \"SXS:BBH:1234\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(simulations)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in this `dict` are essentially also `dict`s with metadata about the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "For each simulation, you need to know its physical parameters — mass ratio, spins, initial separation, eccentricity, etc. — as well as information about the simulation itself and where to find the data.  The `sxs.Metadata` object encapsulates that information, with nice interactive features to help you explore.\n",
    "\n",
    "Just to take an example, let's focus on one particular simulation in the list, the binary black hole simulation with SXS ID `SXS:BBH:0123`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T15:28:09.583431Z",
     "start_time": "2020-09-17T15:28:01.897576Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = simulations[\"SXS:BBH:0123\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, `metadata` is a standard python `dict`, with a few extra bells and whistles.  For example, it looks a bit tidier than your basic `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these fields are more interesting than others.  Presumably, the most interesting ones are the numbers — things like the mass ratio and spins.  You can access them individually just like any `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T15:28:09.611086Z",
     "start_time": "2020-09-17T15:28:09.606616Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata[\"reference_mass_ratio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we also have tab completion when using IPython (or Jupyter).  For example, if you just start with\n",
    "\n",
    "```python\n",
    "metadata[\"reference_m\n",
    "```\n",
    "\n",
    "and then hit tab, you'll see a list of possible completions.  Every key can also be accessed as an attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T15:28:09.618219Z",
     "start_time": "2020-09-17T15:28:09.613509Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata.reference_mass_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also gives you tab completion.\n",
    "\n",
    "Finally, we also provide some backwards compatibility with the older NRAR metadata format, which called for hyphens to be used where we use underscores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T15:28:09.627109Z",
     "start_time": "2020-09-17T15:28:09.622057Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata[\"reference-mass-ratio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain points with the metadata\n",
    "\n",
    "One of the issues that has built up over time is the fact that metadata keys are not entirely consistent.  For example, one key:value pair we see above is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T15:28:09.633039Z",
     "start_time": "2020-09-17T15:28:09.628765Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata[\"reference_eccentricity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might have expected to get a number out of this, but we got a string.  This is because the eccentricity fitting function can't always find a very exact value, and only returns an upper bound.  So if you're sorting through lots of different metadata files, looking for eccentricities — let's say — above 0.1, you might have a line that says\n",
    "\n",
    "```python\n",
    "if metadata[\"reference_eccentricity\"] > 0.1:\n",
    "    do_something()\n",
    "```\n",
    "\n",
    "Unfortunately, once you get to this particular metadata file, that test ***WILL RAISE AN ERROR***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T15:28:09.972770Z",
     "start_time": "2020-09-17T15:28:09.636533Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata[\"reference_eccentricity\"] > 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also many datasets where values are missing.  For example, many of these keys make no sense for simulations with matter (BHNS and NSNS); similarly many critical pieces of information in matter simulations are irrelevant for BBH simulations.\n",
    "\n",
    "We need a more systematic interface to the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain reliever: the dataframe\n",
    "\n",
    "The idea behind these metadata objects is that they should serve as the official records of what was written at the time the simulation was run.  We don't want to be too clever above fixing the pain points, because we might incorrectly change some critical piece of information.\n",
    "\n",
    "*However*, if you are willing to trade the possibility that this will replace data that you could make sense of with NaNs, for the sake of consistency, then the `simulations` object provides a more uniform interface to all the metadata collected in one place, in the form of `simulations.dataframe`.\n",
    "\n",
    "The widely used `pandas` package is designed for precisely this application: analysing tabular data with heterogeneously typed columns.  It provides very powerful features for all sorts of sorting, selection, and statistical analysis.  So we use `pandas` to help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = simulations.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a dataframe (or table) with consistent types, and NaN for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus, we can use the `qgridnext` package to make this cool interactive table (which, unfortunately, will not show up if you are viewing this as a static web page):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qgridnext import show_grid\n",
    "show_grid(df, precision=8, show_toolbar=True, grid_options={\"forceFitColumns\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can sort by a column by clicking on the column header.  You can also filter by value by clicking the <span class=\"fa fa-filter filter-icon\"></span> icon in the header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing that and more, programatically\n",
    "\n",
    "While graphical interfaces are fun, there is more reproducibility and power in programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slices\n",
    "\n",
    "We can slice the dataframe in a dizzying number of ways.  But there are two that are simplest and most reliable.  First, and most easily, we can take standard slices, like the first four elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can select columns to extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"object_types\", \"initial_adot\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine them, we just do them in sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:4][[\"object_types\", \"initial_adot\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests\n",
    "\n",
    "The concept of tests is fairly simply.  For example, we can test whether or not the `object_types` field is equal to `BHNS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"object_types\"] == \"BHNS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a pandas Series object, where most of the results say `False`, but the last few say `True` — because they are the ones for which the `object_types` field is `BHNS`.  Now, we can use this Series just like we would in numpy to extract the items where this test gives us `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"object_types\"] == \"BHNS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Here, we're just looking at the data, so we don't bother with the fancy grid we used above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we might want to combine tests.  This is done by putting each test inside parentheses, and combinging results with `&`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"object_types\"] == \"BHNS\") & (df[\"initial_separation\"] < 52)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the combined test is only `True` if both tests to return `True` — the `&` operator is the boolean AND.  We also have OR with `|` and XOR with `^`, as well as negation with `~` — though this can usually be achieved by changing the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything else, it's convenient to use what we've just learned to separate out the different types of systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BHBH = df[df[\"object_types\"] == \"BHBH\"]\n",
    "BHNS = df[df[\"object_types\"] == \"BHNS\"]\n",
    "NSNS = df[df[\"object_types\"] == \"NSNS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "\n",
    "As with the fancy graphical table above, we can perform a standard sort with respect to any key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BHBH.sort_values(\"initial_separation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But unlike the fancy graphical table above, we can use a function that serves as the sort key.  (This sort of key function is also available in the standard python library's `sorted` function.)  Here, we'll sort by the absolute value of the difference between `initial_separation` and 20.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_field = \"initial_separation\"\n",
    "desired_value = 20.0\n",
    "\n",
    "BHBH.sort_values(sorting_field, key=lambda s: abs(s-desired_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we want the 8 systems with initial separations closest to 20, we can just take them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_field = \"initial_separation\"\n",
    "desired_value = 20.0\n",
    "N = 8\n",
    "\n",
    "BHBH.sort_values(sorting_field, key=lambda s: abs(s-desired_value))[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Pandas also makes it easy to plot the various quantities.  For example, we can make a scatter plot of mass ratio versus $\\chi_{\\mathrm{eff}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BHBH.plot(\"reference_mass_ratio\", \"reference_chi_eff\", kind=\"scatter\")\n",
    "\n",
    "# pandas adds the column labels as axis labels, but we can make them look nicer\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(r\"Mass ratio\")\n",
    "plt.ylabel(r\"$\\chi_\\mathrm{eff}$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:20:13.714437Z",
     "iopub.status.busy": "2024-08-05T21:20:13.713948Z",
     "iopub.status.idle": "2024-08-05T21:20:13.720113Z",
     "shell.execute_reply": "2024-08-05T21:20:13.718943Z",
     "shell.execute_reply.started": "2024-08-05T21:20:13.714411Z"
    }
   },
   "source": [
    "Or we can make histograms of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BHBH[\"initial_ADM_linear_momentum_mag\"].plot.hist(log=True)\n",
    "plt.xlabel(r\"Magnitude of ADM linear momentum\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even make corner plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pp = sns.pairplot(\n",
    "    BHBH[[\"reference_chi_eff\", \"reference_chi1_perp\", \"reference_chi2_perp\", \"reference_mass_ratio\"]].dropna(),\n",
    "    corner=True,\n",
    ")\n",
    "pp.y_vars = [r\"$\\chi_{\\mathrm{eff}}$\", r\"$\\chi_{\\perp,1}$\", r\"$\\chi_{\\perp,2}$\", r\"$q$\"]\n",
    "pp.x_vars = pp.y_vars\n",
    "pp._add_axis_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `simulations` object, especially when agumented with the `dataframe`, provides powerful methods for selecting the particular simulations we are interested in.  Once we have done so, we need to load and interact with the simulations.\n",
    "\n",
    "Continue with the [introduction to the `Simulation` objects](/tutorials/02-Simulation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
